"""
KB Priority-based Ultra-fast Orchestration Agent
Maximum speed optimization with KB-first approach
"""

import json
from typing import Dict, List, Any
from utils.config import AgentConfig
from utils.bedrock_client import BedrockClient


class OptimizedOrchestrationAgent:
    """
    KB Priority-based Ultra-fast Orchestration Agent
    
    Key optimizations:
    - KB_ID exists â†’ KB search priority
    - KB_ID missing â†’ Direct model answer
    - Ultra-minimal English prompts
    - Korean output maintained
    """
    
    def __init__(self, config: AgentConfig):
        self.config = config
        self.bedrock_client = BedrockClient()
    
    def orchestrate(self, context: Dict) -> Dict:
        """Ultra-fast KB-priority orchestration with conversation continuity"""
        try:
            original_query = context.get("original_query", "")
            kb_id = context.get("kb_id", "")
            kb_description = context.get("kb_description", "")
            conversation_history = context.get("conversation_history", [])
            
            # 1. ëŒ€í™” ì—°ì†ì„± ì§ˆë¬¸ ìš°ì„  ì²˜ë¦¬ (KB_ID ì¡´ì¬ ì—¬ë¶€ì™€ ë¬´ê´€)
            if self._is_conversation_continuation(original_query, conversation_history):
                return self._create_direct_answer_result(original_query, "Conversation continuation")
            
            # 2. ë‹¨ìˆœí•œ ì¸ì‚¬ë§ ì²˜ë¦¬
            if self._is_simple_greeting(original_query):
                return self._create_direct_answer_result(original_query, "Simple greeting")
            
            # 3. KB_ID ì¡´ì¬ ì—¬ë¶€ì— ë”°ë¥¸ ìš°ì„ ìˆœìœ„ ê²°ì •
            if not kb_id:
                # KB_ID ì—†ìŒ â†’ ì§ì ‘ ë‹µë³€ (ëŒ€í™” ë§¥ë½ ê³ ë ¤)
                return self._create_direct_answer_result(original_query, "No KB_ID - direct answer with context")
            
            # 4. KB_ID ìˆìŒ â†’ KB ê²€ìƒ‰ ìš°ì„ 
            # ì¬ì‹œë„ í‚¤ì›Œë“œê°€ ìˆëŠ”ì§€ í™•ì¸
            retry_keywords = context.get("retry_keywords", [])
            if retry_keywords:
                print(f"   ğŸ”„ ì¬ì‹œë„ í‚¤ì›Œë“œ ì‚¬ìš©: {retry_keywords}")
                return {
                    "type": "Orchestration",
                    "model": self.config.orchestration_model,
                    "content": f"KB retry search with keywords: {retry_keywords}",
                    "parsed_result": {
                        "needs_kb_search": True,
                        "search_keywords": retry_keywords,
                        "intent": "KB retry search",
                        "confidence": 0.9,
                        "rule_applied": "kb_retry",
                        "reasoning": f"Retry with different keywords: {context.get('retry_reason', 'Previous search insufficient')}",
                        "context_applied": len(conversation_history) > 0
                    },
                    "error": False
                }
            
            # KB ê²€ìƒ‰ í‚¤ì›Œë“œ ìƒì„± (ì´ˆê³ ì†)
            keywords = self._generate_keywords_fast(original_query, kb_description, conversation_history)
            
            return {
                "type": "Orchestration",
                "model": self.config.orchestration_model,
                "content": f"KB search with keywords: {keywords}",
                "parsed_result": {
                    "needs_kb_search": True,
                    "search_keywords": keywords,
                    "intent": "KB search priority",
                    "confidence": 0.95,
                    "rule_applied": "kb_priority",
                    "reasoning": "KB_ID exists - KB search priority",
                    "context_applied": len(conversation_history) > 0
                },
                "error": False
            }
            
        except Exception as e:
            return self._create_error_result(str(e))
    
    def _generate_keywords_fast(self, query: str, kb_description: str, history: List[Dict]) -> List[str]:
        """Ultra-fast keyword generation with minimal prompt"""
        try:
            # ì´ì „ ëŒ€í™” ë§¥ë½ í™•ì¸
            context_info = ""
            if history and len(history) > 0:
                last_user_msg = ""
                for msg in reversed(history):
                    if msg.get("role") == "user":
                        last_user_msg = msg.get("content", "")[:100]
                        break
                if last_user_msg:
                    context_info = f"Previous: {last_user_msg}"
            
            # KB ì„¤ëª… ì •ë³´
            kb_info = f"KB: {kb_description[:100]}" if kb_description else "KB: General knowledge base"
            
            # ì´ˆê°„ë‹¨ ì˜ì–´ í”„ë¡¬í”„íŠ¸ (í† í° ìµœì†Œí™”)
            prompt = f"""Query: {query}
{kb_info}
{context_info}

Generate 3 Korean search keywords for KB search.
Output format: ["keyword1", "keyword2", "keyword3"]"""
            
            response = self.bedrock_client.invoke_model(
                model_id=self.config.orchestration_model,
                prompt=prompt,
                temperature=0.0,  # ì¼ê´€ì„± ìµœëŒ€í™”
                max_tokens=100,   # ìµœì†Œ í† í°
                system_prompt="You are a keyword extraction expert. Generate precise Korean search keywords in JSON array format."
            )
            
            # JSON íŒŒì‹± ì‹œë„
            try:
                import re
                # JSON ë°°ì—´ íŒ¨í„´ ì°¾ê¸°
                json_match = re.search(r'\[.*?\]', response)
                if json_match:
                    keywords_json = json_match.group()
                    keywords = json.loads(keywords_json)
                    if isinstance(keywords, list) and len(keywords) > 0:
                        return keywords[:3]  # ìµœëŒ€ 3ê°œ
            except:
                pass
            
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í´ë°±
            return self._extract_keywords_fallback(query)
            
        except Exception as e:
            return self._extract_keywords_fallback(query)
    
    def _extract_keywords_fallback(self, query: str) -> List[str]:
        """í‚¤ì›Œë“œ ì¶”ì¶œ í´ë°± ë¡œì§"""
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ
        import re
        
        # í•œê¸€ ë‹¨ì–´ ì¶”ì¶œ
        korean_words = re.findall(r'[ê°€-í£]+', query)
        
        # ì˜ì–´ ë‹¨ì–´ ì¶”ì¶œ
        english_words = re.findall(r'[a-zA-Z]+', query)
        
        # ìˆ«ì í¬í•¨ ë‹¨ì–´ ì¶”ì¶œ
        number_words = re.findall(r'[ê°€-í£]*\d+[ê°€-í£]*', query)
        
        all_keywords = korean_words + english_words + number_words
        
        # ì¤‘ë³µ ì œê±° ë° ê¸¸ì´ í•„í„°ë§
        unique_keywords = []
        for keyword in all_keywords:
            if len(keyword) >= 2 and keyword not in unique_keywords:
                unique_keywords.append(keyword)
        
        # ìµœëŒ€ 3ê°œ ë°˜í™˜
        return unique_keywords[:3] if unique_keywords else [query[:20]]
    
    def _is_conversation_continuation(self, query: str, history: List[Dict]) -> bool:
        """ëŒ€í™” ì—°ì†ì„± ì§ˆë¬¸ì¸ì§€ í™•ì¸"""
        if not history or len(history) == 0:
            return False
        
        # ì—°ì†ì„± í‘œí˜„ë“¤
        continuation_patterns = [
            "ë‹¤ìŒì€", "ê·¸ëŸ¼", "ê·¸ëŸ¬ë©´", "ë˜ëŠ”", "ì•„ë‹ˆë©´", "ê·¸ë¦¬ê³ ", "ê·¸ëŸ°ë°",
            "ê·¸ë˜ì„œ", "ê·¸ë ‡ë‹¤ë©´", "ê·¸ëŸ¼ì—ë„", "í•˜ì§€ë§Œ", "ê·¸ëŸ°ë°ë„", "ê·¸ë˜ë„",
            "ê³„ì†", "ì´ì–´ì„œ", "ì¶”ê°€ë¡œ", "ë”", "ë˜", "ê·¸ ì™¸ì—", "ë‹¤ë¥¸",
            "next", "then", "also", "more", "continue", "what about", "how about"
        ]
        
        query_lower = query.lower().strip()
        
        # ì§§ì€ ì—°ì†ì„± ì§ˆë¬¸ (10ì ì´í•˜)
        if len(query.strip()) <= 10:
            for pattern in continuation_patterns:
                if pattern in query_lower:
                    return True
        
        # ì§ˆë¬¸ì´ ì§§ê³  ì´ì „ ëŒ€í™”ê°€ ìˆëŠ” ê²½ìš°
        if len(query.strip()) <= 20 and len(history) > 0:
            # ì˜ë¬¸ì‚¬ë¡œ ì‹œì‘í•˜ëŠ” ì§§ì€ ì§ˆë¬¸
            question_starters = ["ë­", "ë¬´ì—‡", "ì–´ë–¤", "ì–´ë–»ê²Œ", "ì™œ", "ì–¸ì œ", "ì–´ë””", "ëˆ„ê°€", "ì–¼ë§ˆ"]
            for starter in question_starters:
                if query.strip().startswith(starter):
                    return True
        
        return False
    
    def _is_simple_greeting(self, query: str) -> bool:
        """ê°„ë‹¨í•œ ì¸ì‚¬ë§ í™•ì¸"""
        greetings = ["ì•ˆë…•", "hello", "hi", "ì•ˆë…•í•˜ì„¸ìš”", "ì•ˆë…•í•˜ì‹­ë‹ˆê¹Œ"]
        query_lower = query.lower().strip()
        return any(greeting in query_lower for greeting in greetings) and len(query.strip()) < 20
    
    def _create_direct_answer_result(self, query: str, reason: str) -> Dict:
        """ì§ì ‘ ë‹µë³€ ê²°ê³¼ ìƒì„± (ëŒ€í™” ë§¥ë½ í¬í•¨)"""
        return {
            "type": "Orchestration",
            "model": self.config.orchestration_model,
            "content": f"Direct answer required. Reason: {reason}",
            "parsed_result": {
                "needs_kb_search": False,
                "search_keywords": [],
                "intent": "Direct answer with context",
                "confidence": 0.9,
                "rule_applied": "direct_answer",
                "reasoning": reason,
                "context_applied": True,  # ëŒ€í™” ë§¥ë½ ì ìš© í‘œì‹œ
                "requires_conversation_context": True  # ëŒ€í™” ë§¥ë½ í•„ìš” í‘œì‹œ
            },
            "error": False
        }
    
    def _create_error_result(self, error_msg: str) -> Dict:
        """ì—ëŸ¬ ê²°ê³¼ ìƒì„±"""
        return {
            "type": "Orchestration",
            "model": self.config.orchestration_model,
            "content": f"Orchestration error: {error_msg}",
            "parsed_result": {
                "needs_kb_search": False,
                "search_keywords": [],
                "intent": "Error occurred",
                "confidence": 0.0,
                "rule_applied": "error",
                "reasoning": f"Error: {error_msg}",
                "context_applied": False
            },
            "error": True
        }
    
    def get_model_name(self) -> str:
        """í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸ëª… ë°˜í™˜"""
        model_id = self.config.orchestration_model
        if "claude-sonnet-4" in model_id:
            return "Claude 4 (KB-Priority)"
        elif "claude-3-7-sonnet" in model_id:
            return "Claude 3.7 Sonnet (KB-Priority)"
        elif "claude-3-5-sonnet" in model_id:
            return "Claude 3.5 Sonnet (KB-Priority)"
        elif "claude-3-5-haiku" in model_id:
            return "Claude 3.5 Haiku (KB-Priority)"
        elif "nova-lite" in model_id:
            return "Nova Lite (KB-Priority)"
        elif "nova-micro" in model_id:
            return "Nova Micro (KB-Priority)"
        else:
            return f"{model_id.split(':')[0]} (KB-Priority)"


# ê¸°ì¡´ ì½”ë“œì™€ì˜ í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­
OrchestrationAgent = OptimizedOrchestrationAgent
