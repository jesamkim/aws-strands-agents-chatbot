"""
AWS Strands Agents ê¸°ë°˜ ReAct ì±—ë´‡
ê¸°ì¡´ ìˆ˜ë™ ReAct ë£¨í”„ë¥¼ Strands Agents í”„ë ˆì„ì›Œí¬ë¡œ ëŒ€ì²´
"""

import json
import time
from typing import Dict, List, Any, Optional

# Strands import with fallback to mock
try:
    from strands import Agent
    STRANDS_AVAILABLE = True
except ImportError:
    print("âš ï¸ Strands Agents ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Mock ë²„ì „ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    from .mock_strands import MockAgent as Agent
    STRANDS_AVAILABLE = False

from utils.config import AgentConfig
from .strands_tools import StrandsToolsManager


class StrandsReActChatbot:
    """
    AWS Strands Agents ê¸°ë°˜ ReAct ì±—ë´‡
    
    ì£¼ìš” íŠ¹ì§•:
    - Strands Agents í”„ë ˆì„ì›Œí¬ í™œìš©
    - ìë™í™”ëœ ReAct ë£¨í”„
    - ë„êµ¬ ê¸°ë°˜ KB ê²€ìƒ‰ ë° ë¶„ì„
    - ëŒ€í™” ë§¥ë½ ì¸ì‹
    """
    
    def __init__(self, config: AgentConfig):
        self.config = config
        self.tools_manager = StrandsToolsManager(config)
        
        # ë©”ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì—ì´ì „íŠ¸ ìƒì„±
        self.orchestrator = self._create_orchestrator_agent()
        
        # KB ê²€ìƒ‰ ì „ë¬¸ ì—ì´ì „íŠ¸ ìƒì„±
        self.kb_search_agent = self._create_kb_search_agent()
        
        # ë‹µë³€ ìƒì„± ì „ë¬¸ ì—ì´ì „íŠ¸ ìƒì„±
        self.answer_agent = self._create_answer_agent()
    
    def _create_orchestrator_agent(self) -> Agent:
        """ë©”ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì—ì´ì „íŠ¸ ìƒì„±"""
        system_prompt = f"""{self.config.system_prompt or 'ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.'}

ë‹¹ì‹ ì€ ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  ì ì ˆí•œ ì²˜ë¦¬ ë°©ë²•ì„ ê²°ì •í•˜ëŠ” ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°ì…ë‹ˆë‹¤.

**ì£¼ìš” ì—­í• :**
1. ëŒ€í™” ë§¥ë½ ë¶„ì„ (ì—°ì†ì„± ì§ˆë¬¸, ì¸ì‚¬ë§ ë“±)
2. KB ê²€ìƒ‰ í•„ìš”ì„± íŒë‹¨
3. ì ì ˆí•œ ì „ë¬¸ ì—ì´ì „íŠ¸ì—ê²Œ ì‘ì—… ìœ„ì„
4. ìµœì¢… ë‹µë³€ ì¡°ìœ¨

**ì²˜ë¦¬ ìš°ì„ ìˆœìœ„:**
1. ëŒ€í™” ì—°ì†ì„± ì§ˆë¬¸ â†’ ì§ì ‘ ë‹µë³€
2. ê°„ë‹¨í•œ ì¸ì‚¬ë§ â†’ ì§ì ‘ ë‹µë³€  
3. KB_ID ì—†ìŒ â†’ ì¼ë°˜ ì§€ì‹ìœ¼ë¡œ ë‹µë³€
4. KB_ID ìˆìŒ â†’ KB ê²€ìƒ‰ í›„ ë‹µë³€

**ë„êµ¬ ì‚¬ìš© ì§€ì¹¨:**
- conversation_context_analyzer: ë¨¼ì € ëŒ€í™” ë§¥ë½ì„ ë¶„ì„í•˜ì„¸ìš”
- kb_search_tool: KB ê²€ìƒ‰ì´ í•„ìš”í•œ ê²½ìš°ì—ë§Œ ì‚¬ìš©
- citation_generator: ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆì„ ë•Œ Citation ì¶”ê°€

í•­ìƒ í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ì„¸ìš”."""
        
        return Agent(
            system_prompt=system_prompt,
            tools=self.tools_manager.get_all_tools()
        )
    
    def _create_kb_search_agent(self) -> Agent:
        """KB ê²€ìƒ‰ ì „ë¬¸ ì—ì´ì „íŠ¸ ìƒì„±"""
        system_prompt = """ë‹¹ì‹ ì€ Knowledge Base ê²€ìƒ‰ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

**ì£¼ìš” ì—­í• :**
1. ìµœì ì˜ ê²€ìƒ‰ í‚¤ì›Œë“œ ìƒì„±
2. KB ê²€ìƒ‰ ì‹¤í–‰
3. ê²€ìƒ‰ ê²°ê³¼ í’ˆì§ˆ í‰ê°€
4. í•„ìš”ì‹œ ì¬ê²€ìƒ‰ ìˆ˜í–‰

**ê²€ìƒ‰ ì „ëµ:**
- ì´ˆê¸° ê²€ìƒ‰: í•µì‹¬ í‚¤ì›Œë“œ 3ê°œë¡œ ê²€ìƒ‰
- í’ˆì§ˆ í‰ê°€: ê´€ë ¨ì„± ì ìˆ˜ì™€ ë‚´ìš© ê¸¸ì´ í™•ì¸
- ì¬ê²€ìƒ‰: í’ˆì§ˆì´ ë‚®ìœ¼ë©´ ëŒ€ì²´ í‚¤ì›Œë“œë¡œ ì¬ì‹œë„ (ìµœëŒ€ 5íšŒ)

**í’ˆì§ˆ ê¸°ì¤€:**
- 1-2íšŒì°¨: ì—„ê²©í•œ ê¸°ì¤€ (í‰ê·  ì ìˆ˜ 0.5 ì´ìƒ)
- 3-4íšŒì°¨: ì™„í™”ëœ ê¸°ì¤€ (í‰ê·  ì ìˆ˜ 0.4 ì´ìƒ)  
- 5íšŒì°¨: ë§¤ìš° ì™„í™”ëœ ê¸°ì¤€ (í‰ê·  ì ìˆ˜ 0.2 ì´ìƒ)

í•­ìƒ í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ì„¸ìš”."""
        
        return Agent(
            system_prompt=system_prompt,
            tools=[
                self.tools_manager.keyword_generator,
                self.tools_manager.kb_search_tool,
                self.tools_manager.search_quality_assessor
            ]
        )
    
    def _create_answer_agent(self) -> Agent:
        """ë‹µë³€ ìƒì„± ì „ë¬¸ ì—ì´ì „íŠ¸ ìƒì„±"""
        system_prompt = f"""{self.config.system_prompt or 'ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.'}

ë‹¹ì‹ ì€ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

**ë‹µë³€ ìƒì„± ì›ì¹™:**
1. ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ë°˜ë“œì‹œ í™œìš©í•˜ê³  Citation í¬í•¨
2. ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì¼ë°˜ ì§€ì‹ìœ¼ë¡œ ë„ì›€ë˜ëŠ” ë‹µë³€ ì œê³µ
3. ëŒ€í™” ë§¥ë½ì„ ê³ ë ¤í•œ ìì—°ìŠ¤ëŸ¬ìš´ ë‹µë³€
4. êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì •ë³´ ì œê³µ

**Citation ê·œì¹™:**
- ê²€ìƒ‰ ê²°ê³¼ ì‚¬ìš© ì‹œ [1], [2] í˜•íƒœë¡œ ì¶œì²˜ í‘œì‹œ
- ë‹µë³€ ë§ˆì§€ë§‰ì— "**ì°¸ê³  ìë£Œ:**" ì„¹ì…˜ í¬í•¨
- ê²€ìƒ‰ ê²°ê³¼ì— ì—†ëŠ” ì •ë³´ëŠ” ì¶”ì¸¡í•˜ì§€ ì•ŠìŒ

**ëŒ€í™” ì—°ì†ì„±:**
- ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ì •í™•íˆ ê¸°ì–µí•˜ê³  ì°¸ì¡°
- "ë‹¤ìŒì€?", "ê·¸ëŸ¼?" ê°™ì€ ì—°ì†ì„± ì§ˆë¬¸ì— ì ì ˆíˆ ëŒ€ì‘
- ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” íë¦„ ìœ ì§€

í•­ìƒ í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ì„¸ìš”."""
        
        return Agent(
            system_prompt=system_prompt,
            tools=[self.tools_manager.citation_generator]
        )
    
    async def process_query(self, query: str, conversation_history: List[Dict] = None) -> Dict:
        """
        ì‚¬ìš©ì ì¿¼ë¦¬ ì²˜ë¦¬ (Strands Agents ê¸°ë°˜)
        
        Args:
            query: ì‚¬ìš©ì ì§ˆë¬¸
            conversation_history: ëŒ€í™” íˆìŠ¤í† ë¦¬
            
        Returns:
            ì²˜ë¦¬ ê²°ê³¼
        """
        start_time = time.time()
        
        try:
            if conversation_history is None:
                conversation_history = []
            
            # 1ë‹¨ê³„: ëŒ€í™” ë§¥ë½ ë¶„ì„
            context_analysis = await self._analyze_conversation_context(query, conversation_history)
            
            # 2ë‹¨ê³„: ì²˜ë¦¬ ë°©ë²• ê²°ì • ë° ì‹¤í–‰
            if context_analysis.get("is_greeting"):
                result = await self._handle_greeting(query)
            elif context_analysis.get("is_continuation"):
                result = await self._handle_continuation(query, conversation_history)
            elif not self.config.is_kb_enabled():
                result = await self._handle_direct_answer(query, conversation_history)
            else:
                result = await self._handle_kb_search_flow(query, conversation_history, context_analysis)
            
            # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
            processing_time = time.time() - start_time
            
            return {
                "type": "StrandsReAct",
                "content": result.get("answer", "ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."),
                "processing_time": processing_time,
                "context_analysis": context_analysis,
                "search_results": result.get("search_results", []),
                "citations": result.get("citations", []),
                "iterations": result.get("iterations", 1),
                "error": False
            }
            
        except Exception as e:
            return {
                "type": "StrandsReAct",
                "content": f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                "processing_time": time.time() - start_time,
                "error": True
            }
    
    async def _analyze_conversation_context(self, query: str, history: List[Dict]) -> Dict:
        """ëŒ€í™” ë§¥ë½ ë¶„ì„"""
        try:
            # Strands Agentë¥¼ í†µí•œ ë§¥ë½ ë¶„ì„
            context_prompt = f"""ë‹¤ìŒ ëŒ€í™” ë§¥ë½ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:

í˜„ì¬ ì§ˆë¬¸: {query}
ëŒ€í™” íˆìŠ¤í† ë¦¬: {json.dumps(history[-3:], ensure_ascii=False) if history else 'ì—†ìŒ'}

conversation_context_analyzer ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶„ì„í•˜ê³  ê²°ê³¼ë¥¼ JSON í˜•íƒœë¡œ ë°˜í™˜í•˜ì„¸ìš”."""
            
            response = self.orchestrator(context_prompt)
            
            # ì‘ë‹µì—ì„œ JSON ì¶”ì¶œ
            import re
            json_match = re.search(r'\{.*\}', str(response), re.DOTALL)
            if json_match:
                return json.loads(json_match.group())
            
            # í´ë°± ë¶„ì„
            return self._fallback_context_analysis(query, history)
            
        except Exception as e:
            return self._fallback_context_analysis(query, history)
    
    def _fallback_context_analysis(self, query: str, history: List[Dict]) -> Dict:
        """í´ë°± ë§¥ë½ ë¶„ì„"""
        continuation_patterns = ["ë‹¤ìŒì€", "ê·¸ëŸ¼", "ê·¸ëŸ¬ë©´", "ë˜ëŠ”", "ê³„ì†"]
        greetings = ["ì•ˆë…•", "hello", "hi"]
        
        return {
            "is_continuation": any(p in query.lower() for p in continuation_patterns),
            "is_greeting": any(g in query.lower() for g in greetings) and len(query) < 20,
            "has_context": len(history) > 0,
            "needs_kb_search": self.config.is_kb_enabled()
        }
    
    async def _handle_greeting(self, query: str) -> Dict:
        """ì¸ì‚¬ë§ ì²˜ë¦¬"""
        greeting_prompt = f"""ì‚¬ìš©ìê°€ ì¸ì‚¬ë§ì„ í–ˆìŠµë‹ˆë‹¤: "{query}"

ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ì¸ì‚¬ë§ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”. ì–´ë–¤ ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆëŠ”ì§€ ì•ˆë‚´í•˜ì„¸ìš”."""
        
        response = self.answer_agent(greeting_prompt)
        
        return {
            "answer": str(response),
            "search_results": [],
            "citations": [],
            "iterations": 1
        }
    
    async def _handle_continuation(self, query: str, history: List[Dict]) -> Dict:
        """ëŒ€í™” ì—°ì†ì„± ì§ˆë¬¸ ì²˜ë¦¬"""
        # ì´ì „ ëŒ€í™” ë§¥ë½ êµ¬ì„±
        context_text = ""
        if history:
            for msg in history[-4:]:  # ìµœê·¼ 4ê°œ ë©”ì‹œì§€
                role = msg.get("role", "")
                content = msg.get("content", "")
                context_text += f"{role}: {content}\n"
        
        continuation_prompt = f"""ì´ì „ ëŒ€í™” ë§¥ë½:
{context_text}

í˜„ì¬ ì—°ì†ì„± ì§ˆë¬¸: {query}

ì´ì „ ëŒ€í™”ì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ í˜„ì¬ ì§ˆë¬¸ì— ëŒ€í•œ ì ì ˆí•œ ë‹µë³€ì„ ìƒì„±í•´ì£¼ì„¸ìš”.
ì´ì „ ë‹µë³€ì—ì„œ ì–¸ê¸‰í•œ ë‚´ìš©ì„ êµ¬ì²´ì ìœ¼ë¡œ í™•ì¥í•˜ê±°ë‚˜ ë³´ì™„í•˜ì„¸ìš”."""
        
        response = self.answer_agent(continuation_prompt)
        
        return {
            "answer": str(response),
            "search_results": [],
            "citations": [],
            "iterations": 1
        }
    
    async def _handle_direct_answer(self, query: str, history: List[Dict]) -> Dict:
        """ì§ì ‘ ë‹µë³€ ì²˜ë¦¬ (KB ì—†ìŒ)"""
        # ëŒ€í™” ë§¥ë½ í¬í•¨
        context_text = ""
        if history:
            for msg in history[-3:]:
                role = msg.get("role", "")
                content = msg.get("content", "")[:200]
                context_text += f"{role}: {content}\n"
        
        direct_prompt = f"""ì´ì „ ëŒ€í™” ë§¥ë½:
{context_text}

í˜„ì¬ ì§ˆë¬¸: {query}

Knowledge Baseê°€ ì—†ìœ¼ë¯€ë¡œ ì¼ë°˜ì ì¸ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.
ì´ì „ ëŒ€í™”ì™€ ê´€ë ¨ì´ ìˆë‹¤ë©´ ê·¸ ì—°ê´€ì„±ì„ ì–¸ê¸‰í•˜ë©´ì„œ ë‹µë³€í•´ì£¼ì„¸ìš”."""
        
        response = self.answer_agent(direct_prompt)
        
        return {
            "answer": str(response),
            "search_results": [],
            "citations": [],
            "iterations": 1
        }
    
    async def _handle_kb_search_flow(self, query: str, history: List[Dict], context_analysis: Dict) -> Dict:
        """KB ê²€ìƒ‰ í”Œë¡œìš° ì²˜ë¦¬"""
        max_iterations = 5
        current_iteration = 1
        search_results = []
        previous_keywords = []
        
        while current_iteration <= max_iterations:
            print(f"ğŸ”„ KB ê²€ìƒ‰ ë°˜ë³µ {current_iteration}íšŒì°¨")
            
            # í‚¤ì›Œë“œ ìƒì„±
            if current_iteration == 1:
                keywords_result = await self._generate_initial_keywords(query)
            else:
                keywords_result = await self._generate_retry_keywords(query, previous_keywords)
            
            keywords = keywords_result.get("keywords", [])
            if not keywords:
                break
            
            print(f"   ğŸ” ê²€ìƒ‰ í‚¤ì›Œë“œ: {keywords}")
            previous_keywords.extend(keywords)
            
            # KB ê²€ìƒ‰ ì‹¤í–‰
            search_prompt = f"""ë‹¤ìŒ í‚¤ì›Œë“œë¡œ Knowledge Base ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ì„¸ìš”:
í‚¤ì›Œë“œ: {keywords}
ìµœëŒ€ ê²°ê³¼: 5ê°œ

kb_search_toolì„ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰í•˜ê³  ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì„¸ìš”."""
            
            search_response = self.kb_search_agent(search_prompt)
            
            # ê²€ìƒ‰ ê²°ê³¼ ì¶”ì¶œ
            try:
                import re
                json_match = re.search(r'\{.*\}', str(search_response), re.DOTALL)
                if json_match:
                    search_data = json.loads(json_match.group())
                    if search_data.get("success"):
                        search_results = search_data.get("results", [])
            except:
                pass
            
            # í’ˆì§ˆ í‰ê°€
            quality_result = await self._assess_search_quality(search_results, current_iteration)
            
            if quality_result.get("is_sufficient") or current_iteration >= max_iterations:
                print(f"   âœ… ê²€ìƒ‰ ì™„ë£Œ: {quality_result.get('reason')}")
                break
            else:
                print(f"   ğŸ”„ ì¬ì‹œë„ í•„ìš”: {quality_result.get('reason')}")
                current_iteration += 1
        
        # ìµœì¢… ë‹µë³€ ìƒì„±
        answer = await self._generate_final_answer(query, history, search_results, current_iteration)
        
        return {
            "answer": answer,
            "search_results": search_results,
            "citations": self._extract_citations(search_results),
            "iterations": current_iteration
        }
    
    async def _generate_initial_keywords(self, query: str) -> Dict:
        """ì´ˆê¸° í‚¤ì›Œë“œ ìƒì„±"""
        try:
            keywords_prompt = f"""ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•œ ìµœì ì˜ ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ìƒì„±í•˜ì„¸ìš”:
ì§ˆë¬¸: {query}
KB ì„¤ëª…: {self.config.kb_description}

keyword_generator ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ í‚¤ì›Œë“œë¥¼ ìƒì„±í•˜ì„¸ìš”."""
            
            response = self.kb_search_agent(keywords_prompt)
            
            # JSON ì¶”ì¶œ
            import re
            json_match = re.search(r'\{.*\}', str(response), re.DOTALL)
            if json_match:
                return json.loads(json_match.group())
            
            return {"keywords": [query[:20]]}
            
        except Exception as e:
            return {"keywords": [query[:20]]}
    
    async def _generate_retry_keywords(self, query: str, previous_keywords: List[str]) -> Dict:
        """ì¬ì‹œë„ í‚¤ì›Œë“œ ìƒì„±"""
        try:
            retry_prompt = f"""ì´ì „ ê²€ìƒ‰ í‚¤ì›Œë“œë¡œ ì¶©ë¶„í•œ ê²°ê³¼ë¥¼ ì–»ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.
ì§ˆë¬¸: {query}
ì´ì „ í‚¤ì›Œë“œ: {previous_keywords}

keyword_generator ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ëŒ€ì²´ í‚¤ì›Œë“œë¥¼ ìƒì„±í•˜ì„¸ìš”."""
            
            response = self.kb_search_agent(retry_prompt)
            
            # JSON ì¶”ì¶œ
            import re
            json_match = re.search(r'\{.*\}', str(response), re.DOTALL)
            if json_match:
                return json.loads(json_match.group())
            
            return {"keywords": []}
            
        except Exception as e:
            return {"keywords": []}
    
    async def _assess_search_quality(self, search_results: List[Dict], iteration: int) -> Dict:
        """ê²€ìƒ‰ í’ˆì§ˆ í‰ê°€"""
        try:
            quality_prompt = f"""ë‹¤ìŒ ê²€ìƒ‰ ê²°ê³¼ì˜ í’ˆì§ˆì„ í‰ê°€í•˜ì„¸ìš”:
ê²€ìƒ‰ ê²°ê³¼: {json.dumps(search_results, ensure_ascii=False)}
í˜„ì¬ ë°˜ë³µ: {iteration}íšŒì°¨

search_quality_assessor ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ í’ˆì§ˆì„ í‰ê°€í•˜ì„¸ìš”."""
            
            response = self.kb_search_agent(quality_prompt)
            
            # JSON ì¶”ì¶œ
            import re
            json_match = re.search(r'\{.*\}', str(response), re.DOTALL)
            if json_match:
                return json.loads(json_match.group())
            
            return {"is_sufficient": iteration >= 5, "reason": "í‰ê°€ ì‹¤íŒ¨"}
            
        except Exception as e:
            return {"is_sufficient": iteration >= 5, "reason": f"í‰ê°€ ì˜¤ë¥˜: {str(e)}"}
    
    async def _generate_final_answer(self, query: str, history: List[Dict], search_results: List[Dict], iterations: int) -> str:
        """ìµœì¢… ë‹µë³€ ìƒì„±"""
        try:
            # ëŒ€í™” ë§¥ë½ êµ¬ì„±
            context_text = ""
            if history:
                for msg in history[-3:]:
                    role = msg.get("role", "")
                    content = msg.get("content", "")[:200]
                    context_text += f"{role}: {content}\n"
            
            # ê²€ìƒ‰ ê²°ê³¼ í…ìŠ¤íŠ¸ êµ¬ì„±
            results_text = ""
            if search_results:
                for i, result in enumerate(search_results):
                    content = result.get("content", "")[:400]
                    source = result.get("source", "")
                    results_text += f"[{i+1}] {content}...\nì¶œì²˜: {source}\n\n"
            
            answer_prompt = f"""ì´ì „ ëŒ€í™” ë§¥ë½:
{context_text}

í˜„ì¬ ì§ˆë¬¸: {query}

Knowledge Base ê²€ìƒ‰ ê²°ê³¼ ({iterations}íšŒ ê²€ìƒ‰):
{results_text}

ìœ„ì˜ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ì •í™•í•˜ê³  ìƒì„¸í•œ ë‹µë³€ì„ ìƒì„±í•´ì£¼ì„¸ìš”.

**ì¤‘ìš” ìš”êµ¬ì‚¬í•­:**
1. ê²€ìƒ‰ ê²°ê³¼ ì‚¬ìš© ì‹œ ë°˜ë“œì‹œ [1], [2] í˜•íƒœë¡œ Citation í¬í•¨
2. ë‹µë³€ ë§ˆì§€ë§‰ì— "**ì°¸ê³  ìë£Œ:**" ì„¹ì…˜ ì¶”ê°€
3. ê²€ìƒ‰ ê²°ê³¼ì— ì—†ëŠ” ì •ë³´ëŠ” ì¶”ì¸¡í•˜ì§€ ì•ŠìŒ
4. êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ë‹µë³€ ì œê³µ

citation_generator ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ Citationì„ í¬í•¨í•œ ë‹µë³€ì„ ìƒì„±í•˜ì„¸ìš”."""
            
            response = self.answer_agent(answer_prompt)
            return str(response)
            
        except Exception as e:
            return f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    def _extract_citations(self, search_results: List[Dict]) -> List[Dict]:
        """Citation ì •ë³´ ì¶”ì¶œ"""
        citations = []
        for i, result in enumerate(search_results):
            citations.append({
                "id": i + 1,
                "source": result.get("source", f"ì¶œì²˜ {i+1}"),
                "score": result.get("score", 0)
            })
        return citations
    
    def get_model_info(self) -> Dict:
        """ëª¨ë¸ ì •ë³´ ë°˜í™˜"""
        return {
            "framework": "AWS Strands Agents",
            "orchestration_model": self.config.orchestration_model,
            "action_model": self.config.action_model,
            "observation_model": self.config.observation_model,
            "kb_enabled": self.config.is_kb_enabled(),
            "kb_id": self.config.kb_id if self.config.is_kb_enabled() else None
        }
